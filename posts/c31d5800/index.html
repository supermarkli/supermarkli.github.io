<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/video-game.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/video-game.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/video-game.ico">
  <link rel="mask-icon" href="/images/video-game.ico" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous" defer></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"supermarkli.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.23.2","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"agate","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":true,"show_result":true,"style":"default"},"fold":{"enable":false,"height":500}},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="今天来看一下 NVIDIA GPU 的中间表示（PTX）指令。我们以 ld（load）指令为主线，把 PTX 语法 和 GPU 存储层次&#x2F;缓存&#x2F;一致性 串起来理解。">
<meta property="og:type" content="article">
<meta property="og:title" content="ptx-ld指令">
<meta property="og:url" content="https://supermarkli.github.io/posts/c31d5800/index.html">
<meta property="og:site_name" content="吃糠咽菜">
<meta property="og:description" content="今天来看一下 NVIDIA GPU 的中间表示（PTX）指令。我们以 ld（load）指令为主线，把 PTX 语法 和 GPU 存储层次&#x2F;缓存&#x2F;一致性 串起来理解。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-12-13T01:54:37.000Z">
<meta property="article:modified_time" content="2025-12-15T05:30:55.167Z">
<meta property="article:author" content="吃糠咽菜">
<meta property="article:tag" content="note,coding,life">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://supermarkli.github.io/posts/c31d5800/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://supermarkli.github.io/posts/c31d5800/","path":"posts/c31d5800/","title":"ptx-ld指令"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>ptx-ld指令 | 吃糠咽菜</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.5.0/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.7.0/mermaid.min.js","integrity":"sha256-4+IKDqhZ/sXjc8Wtl2/MsxI4e0s1KpEVdbEP7V/Lz8U="}}</script>
  <script src="/js/third-party/tags/mermaid.js" defer></script>



  <script src="/js/third-party/pace.js" defer></script>


  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","mhchem":false,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="吃糠咽菜" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">吃糠咽菜</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">好记性不如烂笔头</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%98%85%E8%AF%BB%E9%A1%BA%E5%BA%8F"><span class="nav-number">1.</span> <span class="nav-text">阅读顺序</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86gpu-%E8%BD%AF%E7%A1%AC%E4%BB%B6%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%B1%82%E6%AC%A1"><span class="nav-number">2.</span> <span class="nav-text">前置知识：GPU 软硬件架构与存储层次</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E5%B1%82%E7%BA%A7%E8%BD%AF%E7%A1%AC%E4%BB%B6%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB"><span class="nav-number">2.1.</span> <span class="nav-text">1. 计算层级：软硬件对应关系</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B1%82%E7%BA%A7%E5%8C%85%E5%90%AB%E5%85%B3%E7%B3%BB%E8%AF%A6%E8%A7%A3"><span class="nav-number">2.1.1.</span> <span class="nav-text">层级包含关系详解</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%98%E5%82%A8%E5%B1%82%E7%BA%A7%E7%89%A9%E7%90%86%E7%A1%AC%E4%BB%B6-vs-%E9%80%BB%E8%BE%91%E7%A9%BA%E9%97%B4"><span class="nav-number">2.2.</span> <span class="nav-text">2. 存储层级：物理硬件 vs 逻辑空间</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%A9%E7%90%86%E7%A1%AC%E4%BB%B6%E6%9E%B6%E6%9E%84%E4%BB%8E%E5%BF%AB%E5%88%B0%E6%85%A2"><span class="nav-number">2.3.</span> <span class="nav-text">物理硬件架构（从快到慢）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BE%A8%E6%9E%90sm-vs-blockshared-vs-l1"><span class="nav-number">2.4.</span> <span class="nav-text">辨析：SM vs Block，Shared vs L1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E7%85%A7%E8%A1%A8%E7%89%A9%E7%90%86%E7%A1%AC%E4%BB%B6-ptx-%E9%80%BB%E8%BE%91%E7%A9%BA%E9%97%B4-cuda-%E4%BD%9C%E7%94%A8%E5%9F%9F"><span class="nav-number">2.5.</span> <span class="nav-text">对照表：物理硬件 ↔ PTX 逻辑空间 ↔ CUDA 作用域</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%86%85%E5%AD%98%E7%A9%BA%E9%97%B4"><span class="nav-number">2.6.</span> <span class="nav-text">逻辑内存空间</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E5%89%8D%E7%BD%AE-1global-memory-%E5%90%88%E5%B9%B6coalescing"><span class="nav-number">2.7.</span> <span class="nav-text">性能前置 1：Global Memory 合并（Coalescing）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%B3%E9%94%AE%E7%B2%92%E5%BA%A6"><span class="nav-number">2.7.1.</span> <span class="nav-text">关键粒度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%88%E5%B9%B6%E5%9C%BA%E6%99%AF%E5%88%86%E6%9E%90"><span class="nav-number">2.7.2.</span> <span class="nav-text">合并场景分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E5%87%86%E5%88%99"><span class="nav-number">2.7.3.</span> <span class="nav-text">优化准则</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E5%89%8D%E7%BD%AE-2shared-memory-bank-conflict"><span class="nav-number">2.8.</span> <span class="nav-text">性能前置 2：Shared Memory Bank Conflict</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF-bank"><span class="nav-number">2.8.1.</span> <span class="nav-text">什么是 Bank？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%86%B2%E7%AA%81%E6%9C%BA%E5%88%B6%E4%B8%8E%E5%AD%98%E5%82%A8%E6%98%A0%E5%B0%84"><span class="nav-number">2.8.2.</span> <span class="nav-text">冲突机制与存储映射</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%80%E5%8F%91%E8%80%85%E8%A7%86%E8%A7%92%E7%9A%84%E6%97%A0%E6%84%9F%E4%BC%98%E5%8C%96"><span class="nav-number">2.8.3.</span> <span class="nav-text">开发者视角的“无感”优化</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ld-%E6%8C%87%E4%BB%A4%E6%A6%82%E8%A7%88%E5%AE%83%E5%88%B0%E5%BA%95%E7%94%B1%E5%93%AA%E4%BA%9B%E9%83%A8%E5%88%86%E7%BB%84%E6%88%90"><span class="nav-number">3.</span> <span class="nav-text">ld 指令概览：它到底由哪些部分组成？</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E5%8F%A5%E5%BC%8F"><span class="nav-number">3.1.</span> <span class="nav-text">核心句式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C%E6%95%B0%E9%95%BF%E4%BB%80%E4%B9%88%E6%A0%B7"><span class="nav-number">3.2.</span> <span class="nav-text">操作数长什么样</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%8E%E5%93%AA%E9%87%8C%E8%AF%BB%E7%8A%B6%E6%80%81%E7%A9%BA%E9%97%B4memory-state-space"><span class="nav-number">4.</span> <span class="nav-text">1. 从哪里读：状态空间（Memory &#x2F; State Space）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%A9%E7%90%86%E6%95%B0%E6%8D%AE%E7%A9%BA%E9%97%B4physical-data-spaces"><span class="nav-number">4.1.</span> <span class="nav-text">1.1 物理数据空间（Physical Data Spaces）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E7%A9%BA%E9%97%B4parameter-space"><span class="nav-number">4.2.</span> <span class="nav-text">1.2 参数空间（Parameter Space）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%9A%E7%94%A8%E5%AF%BB%E5%9D%80generic-addressing"><span class="nav-number">4.3.</span> <span class="nav-text">1.3 通用寻址（Generic Addressing）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%BB%E4%BB%80%E4%B9%88%E6%95%B0%E6%8D%AE%E5%BD%A2%E7%8A%B6data-shape"><span class="nav-number">5.</span> <span class="nav-text">2. 读什么：数据形状（Data Shape）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8Bfundamental-types"><span class="nav-number">5.1.</span> <span class="nav-text">2.1 基本数据类型（Fundamental Types）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E5%8C%96%E5%8A%A0%E8%BD%BDvectorized-load"><span class="nav-number">5.2.</span> <span class="nav-text">2.2 向量化加载（Vectorized Load）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%B9%E7%90%86%E4%B8%8E%E8%A1%A8%E9%9D%A2%E7%B1%BB%E5%9E%8Btexture-surface"><span class="nav-number">5.3.</span> <span class="nav-text">2.3 纹理与表面类型（Texture &amp; Surface）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%8E%E4%B9%88%E8%AF%BB%E7%BC%93%E5%AD%98%E6%8F%90%E7%A4%BAcaching-hints"><span class="nav-number">6.</span> <span class="nav-text">3. 怎么读：缓存提示（Caching &amp; Hints）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E4%B9%A6%E9%A6%86%E6%A8%A1%E5%9E%8B%E5%AD%98%E5%82%A8%E5%B1%82%E6%AC%A1%E4%B8%8E%E7%BC%93%E5%AD%98%E8%B7%AF%E5%BE%84"><span class="nav-number">6.1.</span> <span class="nav-text">图书馆模型：存储层次与缓存路径</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%A0%E7%BB%9F%E7%BC%93%E5%AD%98%E6%93%8D%E4%BD%9C%E7%AC%A6legacy-cache-operators"><span class="nav-number">6.2.</span> <span class="nav-text">3.1 传统缓存操作符（Legacy Cache Operators）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%8E%B0%E4%BB%A3-l1l2-%E7%B2%BE%E7%BB%86%E6%8E%A7%E5%88%B6cache-eviction-policy"><span class="nav-number">6.3.</span> <span class="nav-text">3.2 现代 L1&#x2F;L2 精细控制（Cache Eviction Policy）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9D%9E%E4%B8%80%E8%87%B4%E6%80%A7%E8%AF%BB%E5%8F%96non-coherent-access"><span class="nav-number">6.4.</span> <span class="nav-text">3.3 非一致性读取（Non-Coherent Access）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AD%A3%E7%A1%AE%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7%E8%AF%AD%E4%B9%89%E4%B8%8E%E5%90%8C%E6%AD%A5%E4%BD%9C%E7%94%A8%E5%9F%9Fconsistency-scope"><span class="nav-number">7.</span> <span class="nav-text">4. 正确性：一致性语义与同步作用域（Consistency &amp; Scope）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E8%AF%AD%E4%B9%89semantics"><span class="nav-number">7.1.</span> <span class="nav-text">4.1 内存语义（Semantics）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%8C%E6%AD%A5%E4%BD%9C%E7%94%A8%E5%9F%9Fscope"><span class="nav-number">7.2.</span> <span class="nav-text">4.2 同步作用域（Scope）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C%E6%95%B0%E7%BB%86%E8%8A%82%E5%86%99-ptx-%E6%97%B6%E6%9C%80%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E7%A7%8D%E5%9C%B0%E5%9D%80%E5%BD%A2%E5%BC%8F"><span class="nav-number">8.</span> <span class="nav-text">5. 操作数细节：写 PTX 时最常见的几种地址形式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E6%93%8D%E4%BD%9C%E6%95%B0destination"><span class="nav-number">8.1.</span> <span class="nav-text">5.1 目标操作数（Destination）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%BA%90%E5%9C%B0%E5%9D%80address"><span class="nav-number">8.2.</span> <span class="nav-text">5.2 源地址（Address）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%B9%E6%AE%8A%E5%BD%A2%E5%BC%8F"><span class="nav-number">8.3.</span> <span class="nav-text">5.3 特殊形式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF%E4%BB%8E%E8%83%BD%E7%94%A8%E5%88%B0%E8%83%BD%E8%B0%83%E4%BC%98"><span class="nav-number">9.</span> <span class="nav-text">6. 学习路线（从能用到能调优）</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="吃糠咽菜"
      src="/images/csnr.jpg">
  <p class="site-author-name" itemprop="name">吃糠咽菜</p>
  <div class="site-description" itemprop="description">一些乱七八糟的笔记</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">47</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">88</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/supermarkli" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;supermarkli" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:12110504@mail.sustech.edu.cn" title="E-Mail → mailto:12110504@mail.sustech.edu.cn" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://supermarkli.github.io/posts/c31d5800/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/csnr.jpg">
      <meta itemprop="name" content="吃糠咽菜">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="吃糠咽菜">
      <meta itemprop="description" content="一些乱七八糟的笔记">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="ptx-ld指令 | 吃糠咽菜">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          ptx-ld指令
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-12-13 09:54:37" itemprop="dateCreated datePublished" datetime="2025-12-13T09:54:37+08:00">2025-12-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-12-15 13:30:55" itemprop="dateModified" datetime="2025-12-15T13:30:55+08:00">2025-12-15</time>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>12k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>21 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>今天来看一下 NVIDIA GPU 的中间表示（PTX）指令。我们以 <code>ld</code>（load）指令为主线，把 <strong>PTX 语法</strong> 和 <strong>GPU 存储层次/缓存/一致性</strong> 串起来理解。 <span id="more"></span></p>
<h2 id="阅读顺序">阅读顺序</h2>
<ul>
<li><strong>先补前置</strong>：GPU 的“物理存储”和 PTX 的“逻辑状态空间”是什么关系，以及访问性能的两大坑：Global 合并访问、Shared Bank Conflict<br />
</li>
<li><strong>再看 <code>ld</code> 拆解</strong>：<code>ld = 状态空间 + 数据形状 + 缓存/一致性 + 操作数</code><br />
</li>
<li><strong>最后看比喻</strong>：用“图书馆模型 / 装修队模型”把缓存提示与 acquire/release 的抽象规则落地成直觉</li>
</ul>
<hr />
<h2 id="前置知识gpu-软硬件架构与存储层次">前置知识：GPU 软硬件架构与存储层次</h2>
<h3 id="计算层级软硬件对应关系">1. 计算层级：软硬件对应关系</h3>
<p>在深入指令之前，先用一张表对齐 <strong>CUDA 软件概念</strong> 与 <strong>GPU 硬件实体</strong>：</p>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">软件概念 (CUDA/PTX)</th>
<th style="text-align: left;">硬件实体 (GPU Hardware)</th>
<th style="text-align: left;">关系与调度 (Scheduling)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Grid (网格)</strong></td>
<td style="text-align: left;"><strong>Device (整个 GPU)</strong></td>
<td style="text-align: left;">一个 Kernel 启动生成一个 Grid。</td>
</tr>
<tr class="even">
<td style="text-align: left;"><em>(Cluster - Hopper)</em></td>
<td style="text-align: left;"><strong>GPC ⊇ TPC</strong></td>
<td style="text-align: left;"><strong>GPC</strong> (Graphics Processing Cluster) 是最高级物理分区，包含多个 TPC；<strong>TPC</strong> (Texture Processing Cluster) 通常包含 2 个 SM。</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Block / CTA (线程块)</strong></td>
<td style="text-align: left;"><strong>SM (大车间 / Streaming Multiprocessor)</strong></td>
<td style="text-align: left;">Block 是调度单位。<strong>Block 被分发给 SM</strong>。一个 SM 资源丰富，可同时驻留多个 Block；但一个 Block 必须整体在一个 SM 内运行。</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Warp (线程束)</strong></td>
<td style="text-align: left;"><strong>Warp Scheduler (调度器)</strong></td>
<td style="text-align: left;">32 个线程的集合，是<strong>硬件执行指令的最小单位</strong>（SIMT）。</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Thread (线程)</strong></td>
<td style="text-align: left;"><strong>Core (工位 / CUDA Core)</strong></td>
<td style="text-align: left;">最小逻辑单位，映射到具体的运算单元上执行。</td>
</tr>
</tbody>
</table>
<h4 id="层级包含关系详解">层级包含关系详解</h4>
<p>这几个概念是<strong>包含</strong>关系，且大小通常在<strong>运行时（Runtime）</strong>动态决定：</p>
<ol type="1">
<li><strong>Grid ⊇ Block</strong>：
<ul>
<li><strong>包含关系</strong>：一个 Grid 包含 <span class="math inline">\(N\)</span> 个 Block。</li>
<li><strong>是固定的吗？</strong> <strong>代码写完时不固定，程序跑起来（Kernel Launch）那一刻固定</strong>。你可以在 Host 代码里动态计算 <code>gridDim</code>（例如 <code>num_blocks = (data_size + 255) / 256</code>），每次启动 Kernel 都可以不一样。</li>
<li><strong>规模</strong>：一个 Grid 可以包含数十亿个 Block（只要显存不爆），硬件会自动排队调度。</li>
</ul></li>
<li><strong>Block ⊇ Thread</strong>：
<ul>
<li><strong>包含关系</strong>：一个 Block 包含 <span class="math inline">\(M\)</span> 个 Thread。</li>
<li><strong>限制</strong>：受限于硬件寄存器和 SM 资源，现代架构通常限制 <strong>Block Size <span class="math inline">\(\le\)</span> 1024</strong>。</li>
<li><strong>协作</strong>：同一个 Block 内的 Thread 可以通过 Shared Memory 交换数据，并用 <code>__syncthreads()</code> 同步；<strong>跨 Block 的 Thread 通常无法直接协作</strong>（除非通过 Global Memory 这种慢速手段）。</li>
</ul></li>
<li><strong>Device ⊇ Grid</strong>：
<ul>
<li><strong>并发性</strong>：在旧架构中，Device 一次通常只专心跑一个 Grid。但在现代架构（支持 Concurrent Kernels / Hyper-Q），如果一个 Grid 很小（只占用了几个 SM），Device 可以<strong>同时运行其他 Grid</strong>，填满剩余的 SM 资源。</li>
</ul></li>
</ol>
<blockquote>
<p><strong>比喻总结</strong>：</p>
<ul>
<li><strong>Device</strong> = <strong>整个工地</strong>。</li>
<li><strong>Grid</strong> = <strong>一个工程项目</strong>（如建一栋楼）。工地够大时，可以同时开工好几个项目（并发 Kernel）。</li>
<li><strong>Block</strong> = <strong>施工队</strong>。一个项目被分包给 100 个施工队，大家领了任务单（BlockID）各自去找空闲的车间（SM）干活。</li>
<li><strong>Thread</strong> = <strong>工人</strong>。每个施工队里固定有 128 或 256 个工人，他们必须同进同退。</li>
</ul>
</blockquote>
<h3 id="存储层级物理硬件-vs-逻辑空间">2. 存储层级：物理硬件 vs 逻辑空间</h3>
<p>要理解 <code>ld</code>，必须把 <strong>“物理硬件存储（Physical Hardware）”</strong> 和 <strong>“逻辑内存空间（Logical Memory Space / State Space）”</strong> 分开看：前者决定延迟/带宽/缓存路径，后者决定你在 PTX 里写什么后缀（<code>.global/.shared/.local/...</code>）。</p>
<h3 id="物理硬件架构从快到慢">物理硬件架构（从快到慢）</h3>
<ol type="1">
<li><strong>寄存器堆（Register File）</strong>：在 SM 内部，延迟最低、带宽最高、容量最小。<br />
</li>
<li><strong>L1 Cache / Shared Memory（片上 SRAM）</strong>：在 SM 内部，低延迟高带宽；在 Volta+ 等架构上两者往往共享同一块物理 SRAM，可配置切分比例。<br />
</li>
<li><strong>Texture / Constant Cache（专用只读缓存）</strong>：
<ul>
<li><strong>Texture Cache</strong>：针对 2D/3D 空间局部性优化的只读缓存，早期是独立硬件，现代架构中逐渐融入 L1 系统。</li>
<li><strong>Constant Cache</strong>：针对广播读取（所有线程读同一地址）优化的只读缓存。</li>
</ul></li>
<li><strong>L2 Cache</strong>：片上但在所有 SM 之外，<strong>所有 SM 共享</strong>，是通往显存的统一缓冲点。<br />
</li>
<li><strong>Device Memory / DRAM（显存）</strong>：片外，容量大、延迟高（数百周期）。</li>
</ol>
<h3 id="辨析sm-vs-blockshared-vs-l1">辨析：SM vs Block，Shared vs L1</h3>
<ul>
<li><strong>SM（Streaming Multiprocessor）</strong>：硬件实体（<strong>“大车间”</strong>）。它内部包含许多 Core（运算单元/工位）和共享资源（L1/Shared Mem）。<br />
</li>
<li><strong>Block（Thread Block/CTA）</strong>：软件任务包（<strong>“施工小队”</strong>）。调度器把施工小队（Block）分发给车间（SM）；一个车间空间足够大，可同时容纳多个小队并行干活，但一个小队全员必须待在同一个车间里。<br />
</li>
<li><strong>Shared Memory</strong>：Block 内共享、可控。<br />
</li>
<li><strong>L1 Cache</strong>：SM 级共享、不可控（硬件自动管理的“公共书架”）。多个 Block 可能共享同一个 L1，但 <strong>不能把 L1 当通信媒介</strong>（无法控制生存期/驱逐）。<br />
</li>
<li><strong>CTA (Cooperative Thread Array)</strong>：是 PTX 指令集（汇编/硬件层面）用的名字，其实就是Block。</li>
</ul>
<h3 id="对照表物理硬件-ptx-逻辑空间-cuda-作用域">对照表：物理硬件 ↔ PTX 逻辑空间 ↔ CUDA 作用域</h3>
<blockquote>
<p>记忆要点：<strong>PTX 的 <code>.global/.shared/...</code> 是“逻辑状态空间”</strong>；而 <strong>L1/L2 是“缓存层”</strong>，通常不能像状态空间那样被直接寻址（更多通过 <code>ld/st</code> 的 cache hints 影响路径/策略）。</p>
</blockquote>
<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">物理硬件（Physical）</th>
<th style="text-align: left;">PTX 逻辑空间 / 写法（Logical / PTX）</th>
<th style="text-align: left;">CUDA 作用域（Scope）</th>
<th style="text-align: left;">例子/直觉</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">寄存器堆（Register File）</td>
<td style="text-align: left;"><strong>寄存器操作数</strong>：<code>%r/%f/%p/...</code>（不是 <code>.reg</code> 这种空间后缀）</td>
<td style="text-align: left;"><strong>Thread 私有</strong></td>
<td style="text-align: left;">临时变量，最快</td>
</tr>
<tr class="even">
<td style="text-align: left;">片上 SRAM（Shared Memory 区）</td>
<td style="text-align: left;"><strong><code>.shared</code></strong></td>
<td style="text-align: left;"><strong>Block/CTA 内共享</strong></td>
<td style="text-align: left;">线程块内协作的“白板”</td>
</tr>
<tr class="odd">
<td style="text-align: left;">片上 SRAM（L1 Cache 区）</td>
<td style="text-align: left;"><strong>无直接对应的 PTX 状态空间</strong>（常缓存 <code>.global/.local</code> 访问）</td>
<td style="text-align: left;"><strong>SM 级共享（跨 Block 共享资源，但不可控）</strong></td>
<td style="text-align: left;">自动管理的“公共书架”</td>
</tr>
<tr class="even">
<td style="text-align: left;">L2 Cache（片上，跨 SM 共享）</td>
<td style="text-align: left;"><strong>无直接对应的 PTX 状态空间</strong>（常缓存 <code>.global/.local/.const</code> 访问）</td>
<td style="text-align: left;"><strong>GPU 级共享</strong></td>
<td style="text-align: left;">所有 SM 共享的“大厅借阅架”</td>
</tr>
<tr class="odd">
<td style="text-align: left;">DRAM / 显存（Device Memory）</td>
<td style="text-align: left;"><strong><code>.global/.local/.const/.param/.tex</code></strong> 等的最终落点（以及它们的映射区域）</td>
<td style="text-align: left;"><strong>取决于空间</strong>：<code>.global</code>=Grid；<code>.local</code>=Thread；<code>.const</code>=Grid（只读）</td>
<td style="text-align: left;">最大最慢的“地下仓库”</td>
</tr>
</tbody>
</table>
<h3 id="逻辑内存空间">逻辑内存空间</h3>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">逻辑空间 (PTX)</th>
<th style="text-align: left;">作用域 (Scope)</th>
<th style="text-align: left;">典型物理位置</th>
<th style="text-align: left;">缓存/路径</th>
<th style="text-align: left;">关键点</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Registers</strong></td>
<td style="text-align: left;">Thread 私有</td>
<td style="text-align: left;">Register File</td>
<td style="text-align: left;">N/A</td>
<td style="text-align: left;">最快，编译器分配</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong><code>.shared</code></strong></td>
<td style="text-align: left;">Block/CTA 共享</td>
<td style="text-align: left;">片上 SRAM</td>
<td style="text-align: left;">不走 L1/L2（逻辑上）</td>
<td style="text-align: left;">需关注 Bank Conflict</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong><code>.global</code></strong></td>
<td style="text-align: left;">Grid/全局</td>
<td style="text-align: left;">DRAM</td>
<td style="text-align: left;">通常走 L2/L1（视架构/提示）</td>
<td style="text-align: left;">需合并访问与对齐</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong><code>.local</code></strong></td>
<td style="text-align: left;">Thread 私有</td>
<td style="text-align: left;">通常是 DRAM（寄存器溢出）</td>
<td style="text-align: left;">可能被 L1/L2 缓存</td>
<td style="text-align: left;">“Local” 不等于 “片上”</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong><code>.const</code></strong></td>
<td style="text-align: left;">全局只读</td>
<td style="text-align: left;">DRAM</td>
<td style="text-align: left;">Constant Cache</td>
<td style="text-align: left;">Warp 广播式读取很快</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong><code>.tex</code></strong></td>
<td style="text-align: left;">全局只读</td>
<td style="text-align: left;">DRAM</td>
<td style="text-align: left;">Texture Cache 路径</td>
<td style="text-align: left;">擅长 2D/3D 局部性</td>
</tr>
</tbody>
</table>
<h3 id="性能前置-1global-memory-合并coalescing">性能前置 1：Global Memory 合并（Coalescing）</h3>
<p>在 SIMT（单指令多线程）架构下，当一个 Warp（32个线程）执行同一条加载/存储指令时，内存控制器（Memory Controller）会将这 32 个独立的内存请求，聚合（Coalesce）为<strong>最少数量的硬件内存事务（Memory Transactions）</strong>的过程。</p>
<p>可以把它想象成<strong>拼车</strong>：如果 32 个线程都要去相邻的内存地址，他们可以坐同一辆“大巴”（一个事务）一次性到达；如果要去分散的地方，就得派 32 辆“出租车”（32 个事务），极大浪费带宽。</p>
<h4 id="关键粒度">关键粒度</h4>
<p>显存控制器与 DRAM 之间的物理传输并非以“字节”为单位，而是以<strong>事务（Transaction）</strong>为单位。事务传输的数据量通常对应以下两种粒度：</p>
<ul>
<li><strong>Sector（扇区）</strong>：32 Bytes。这是现代 GPU 硬件传输的<strong>最小单位</strong>，即便你只需要 4 字节数据，硬件也必须发起一个 32 字节的事务。</li>
<li><strong>Cache Line（缓存行）</strong>：128 Bytes。通常由 4 个连续的 Sector 组成，是缓存系统的管理单位。</li>
</ul>
<p><strong>注意</strong>：在现代架构中，如果数据未对齐或分散，GPU 可以只发起 32B 的事务（加载单个 Sector），而不必像旧架构那样强制加载整个 128B，这减少了无效数据的传输。</p>
<h4 id="合并场景分析">合并场景分析</h4>
<ul>
<li><strong>完美合并 (Coalesced)</strong>：
<ul>
<li><strong>场景</strong>：Warp 内 32 个线程连续访问一段对齐的内存（如 <code>float data[32]</code>）。</li>
<li><strong>结果</strong>：数据恰好占满 4 个 Sector (4 * 32B = 128B)。硬件只需发射 <strong>1 个 128B 事务</strong>。</li>
<li><strong>效率</strong>：有效带宽利用率 100%。</li>
</ul></li>
<li><strong>未合并 (Uncoalesced)</strong>：
<ul>
<li><strong>场景</strong>：线程访问地址分散（Stride 很大），或者首地址未对齐（Offset = 1）。</li>
<li><strong>结果</strong>：需要发射 <strong>N 个 32B 事务</strong> 来覆盖所有请求。</li>
<li><strong>效率</strong>：例如每个事务只为了取 4B 数据却搬运了 32B，有效利用率仅 1/8 (12.5%)。</li>
</ul></li>
</ul>
<h4 id="优化准则">优化准则</h4>
<ol type="1">
<li><strong>空间局部性</strong>：确保 Warp 中相邻的线程（Thread ID <span class="math inline">\(N, N+1\)</span>）访问内存中相邻的地址。</li>
<li><strong>对齐</strong>：访问的首地址最好是 32 或 128 字节的倍数。</li>
</ol>
<h3 id="性能前置-2shared-memory-bank-conflict">性能前置 2：Shared Memory Bank Conflict</h3>
<h4 id="什么是-bank">什么是 Bank？</h4>
<p>共享内存被物理划分为 32 个等宽的内存模块，称为 <strong>Banks</strong>（存储体）。</p>
<ul>
<li><strong>数量</strong>：32 个（对应 Warp 中的 32 个线程）。</li>
<li><strong>宽度</strong>：每个 Bank 宽度通常为 4 字节（32-bits）。</li>
<li><strong>映射</strong>：地址 <span class="math inline">\(A\)</span> 会被映射到 <code>Bank ID = (A / 4) % 32</code>。这意味着相邻的 <code>int</code> 元素（0, 1, 2...）分别落在 Bank 0, Bank 1, Bank 2... 中。</li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">数组索引</th>
<th style="text-align: left;">data[0]</th>
<th style="text-align: left;">data[1]</th>
<th style="text-align: left;">...</th>
<th style="text-align: left;">data[31]</th>
<th style="text-align: left;">data[32]</th>
<th style="text-align: left;">...</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Bank ID</strong></td>
<td style="text-align: left;"><strong>0</strong></td>
<td style="text-align: left;"><strong>1</strong></td>
<td style="text-align: left;">...</td>
<td style="text-align: left;"><strong>31</strong></td>
<td style="text-align: left;"><strong>0</strong></td>
<td style="text-align: left;">...</td>
</tr>
</tbody>
</table>
<h4 id="冲突机制与存储映射">冲突机制与存储映射</h4>
<p><strong>1. 核心规则</strong></p>
<ul>
<li><strong>无冲突</strong>：Warp 线程访问<strong>不同的 Bank</strong>（1个周期）。</li>
<li><strong>Bank 冲突</strong>：多个线程访问<strong>同一个 Bank</strong> 的<strong>不同地址</strong>（硬件串行化，最坏慢32倍）。</li>
<li><strong>广播 (Broadcast)</strong>：多个线程访问<strong>同一个 Bank</strong> 的<strong>同一个地址</strong>（无冲突，硬件广播数据）。</li>
</ul>
<p><strong>2. 案例分析：二维数组的陷阱与 Padding</strong></p>
<p>假设我们声明 <code>__shared__ int matrix[32][32];</code>。</p>
<p><strong>Padding 前：32路冲突</strong></p>
<p>由于是行主序存储，Row 0 的末尾 (Bank 31) 紧接着 Row 1 的开头 (Bank 0)。</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">索引</th>
<th style="text-align: left;">Col 0</th>
<th style="text-align: left;">Col 1</th>
<th style="text-align: left;">...</th>
<th style="text-align: left;">Col 31</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Row 0</strong></td>
<td style="text-align: left;"><strong>Bank 0</strong></td>
<td style="text-align: left;">Bank 1</td>
<td style="text-align: left;">...</td>
<td style="text-align: left;">Bank 31</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Row 1</strong></td>
<td style="text-align: left;"><strong>Bank 0</strong></td>
<td style="text-align: left;">Bank 1</td>
<td style="text-align: left;">...</td>
<td style="text-align: left;">Bank 31</td>
</tr>
<tr class="odd">
<td style="text-align: left;">...</td>
<td style="text-align: left;">...</td>
<td style="text-align: left;">...</td>
<td style="text-align: left;">...</td>
<td style="text-align: left;">...</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Row 31</strong></td>
<td style="text-align: left;"><strong>Bank 0</strong></td>
<td style="text-align: left;">Bank 1</td>
<td style="text-align: left;">...</td>
<td style="text-align: left;">Bank 31</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>行访问 (Good)</strong>：<code>val = matrix[row][tid]</code>。无冲突。</li>
<li><strong>列访问 (Bad)</strong>：<code>val = matrix[tid][col]</code>。所有线程访问同一列（如 Col 0），全部命中 <strong>Bank 0</strong>，造成 <strong>32-way Conflict</strong>。</li>
</ul>
<p><strong>Padding 后：错位消除冲突</strong></p>
<p>声明数组时<strong>多加一列</strong>：<code>__shared__ int matrix[32][33];</code>。虽然每行浪费了一个 <code>int</code>，但彻底改变了映射。</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">索引</th>
<th style="text-align: left;">Col 0</th>
<th style="text-align: left;">Col 1</th>
<th style="text-align: left;">...</th>
<th style="text-align: left;">Col 31</th>
<th style="text-align: left;">(Padding)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Row 0</strong></td>
<td style="text-align: left;"><strong>Bank 0</strong></td>
<td style="text-align: left;">Bank 1</td>
<td style="text-align: left;">...</td>
<td style="text-align: left;">Bank 31</td>
<td style="text-align: left;">Bank 0</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Row 1</strong></td>
<td style="text-align: left;"><strong>Bank 1</strong></td>
<td style="text-align: left;">Bank 2</td>
<td style="text-align: left;">...</td>
<td style="text-align: left;">Bank 0</td>
<td style="text-align: left;">Bank 1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Row 2</strong></td>
<td style="text-align: left;"><strong>Bank 2</strong></td>
<td style="text-align: left;">Bank 3</td>
<td style="text-align: left;">...</td>
<td style="text-align: left;">Bank 1</td>
<td style="text-align: left;">Bank 2</td>
</tr>
</tbody>
</table>
<ul>
<li>Row 0 结束于 Bank 31，Padding 占用了 Bank 0（下一行的起始被推迟）。</li>
<li>Row 1 从 <strong>Bank 1</strong> 开始。</li>
<li><strong>列访问</strong>时：Thread 0 <span class="math inline">\(\to\)</span> Bank 0，Thread 1 <span class="math inline">\(\to\)</span> Bank 1 ... <strong>冲突完全消除</strong>。</li>
</ul>
<h4 id="开发者视角的无感优化">开发者视角的“无感”优化</h4>
<p>你可能会问：<em>那我们在写代码填数据的时候，是不是要小心避开第 33 列？</em></p>
<p><strong>完全正确</strong>。</p>
<ul>
<li><strong>逻辑上</strong>：我们的业务逻辑依然是处理 <span class="math inline">\(32 \times 32\)</span> 的数据。在写循环时，依然是 <code>0</code> 到 <code>31</code>。第 33 列（索引 <code>[32]</code>）虽然存在，但我们<strong>视而不见</strong>，不读也不写。它仅仅是一个物理上的“占位符（Bubble）”，作用是把下一行的起始地址在 Bank 上往后“挤”一位。</li>
<li><strong>对 Bank 无感</strong>：Padding 的最大魅力在于<strong>解耦</strong>。你只需要在<strong>定义数据结构</strong>时做一个微小的改动（<code>[32][32]</code> <span class="math inline">\(\to\)</span> <code>[32][33]</code>），后续所有的<strong>算法逻辑代码</strong>（比如矩阵乘法、转置）完全不需要为了适应硬件而重写。硬件会自动将原本冲突的列访问请求，优雅地分发到不同的 Bank 中。</li>
</ul>
<hr />
<h2 id="ld-指令概览它到底由哪些部分组成"><code>ld</code> 指令概览：它到底由哪些部分组成？</h2>
<p>一条 <code>ld</code> 指令可以拆成三块（也是你阅读 PTX 手册时最常见的结构）：</p>
<ul>
<li><strong>opcode（操作码）</strong>：指令名，例如 <code>ld</code>。<br />
</li>
<li><strong>modifiers（修饰符）</strong>：一串后缀，定义“从哪读、读什么、怎么读、是否需要一致性语义”。<br />
</li>
<li><strong>operands（操作数）</strong>：目标寄存器、源地址（以及可选偏移/策略参数）等。</li>
</ul>
<h3 id="核心句式">核心句式</h3>
<p>所有 <code>ld</code> 读起来都可以按同一个逻辑理解：</p>
<blockquote>
<p><strong><code>ld</code></strong> + <strong>状态空间（从哪读）</strong> + <strong>数据形状（读什么）</strong> + <strong>缓存/一致性（怎么读，是否要守规矩）</strong> + <strong>操作数（存哪去、从哪读）</strong></p>
</blockquote>
<h3 id="操作数长什么样">操作数长什么样</h3>
<ul>
<li><strong>目标寄存器（Destination, <code>d</code>）</strong>：加载结果进入虚拟寄存器（如 <code>%r1/%f2/%p0</code>）。向量化时目标是寄存器元组。<br />
</li>
<li><strong>源地址（Address, <code>[a]</code>）</strong>：<code>[%rd1]</code> 或 <code>[%rd1 + imm]</code> 这种“基址 + 偏移”形式；也可能是符号名 <code>[var]</code>。</li>
</ul>
<hr />
<h2 id="从哪里读状态空间memory-state-space">1. 从哪里读：状态空间（Memory / State Space）</h2>
<p>这是指令的“定语”，决定了你去哪个仓库拿数据。在 PTX 中，显式指定状态空间（State Space）能帮助编译器生成更高效的机器码。</p>
<h3 id="物理数据空间physical-data-spaces">1.1 物理数据空间（Physical Data Spaces）</h3>
<p>这些修饰符直接对应硬件上的存储位置：</p>
<table style="width:100%;">
<colgroup>
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">修饰符</th>
<th style="text-align: left;">空间名称</th>
<th style="text-align: left;">物理位置</th>
<th style="text-align: left;">作用域</th>
<th style="text-align: left;">地址位宽</th>
<th style="text-align: left;">典型用途</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong><code>.global</code></strong></td>
<td style="text-align: left;">全局内存</td>
<td style="text-align: left;">显存 (DRAM)</td>
<td style="text-align: left;">Grid (所有线程)</td>
<td style="text-align: left;">64-bit</td>
<td style="text-align: left;">存放海量数据，所有线程共享。需注意合并访问。</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong><code>.shared</code></strong></td>
<td style="text-align: left;">共享内存</td>
<td style="text-align: left;">片上 SRAM</td>
<td style="text-align: left;">CTA (线程块)</td>
<td style="text-align: left;">32-bit</td>
<td style="text-align: left;">线程块内的高速通信，用户手动管理的缓存。</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong><code>.local</code></strong></td>
<td style="text-align: left;">局部内存</td>
<td style="text-align: left;">显存 (DRAM)</td>
<td style="text-align: left;">Thread (线程私有)</td>
<td style="text-align: left;">64-bit</td>
<td style="text-align: left;"><strong>陷阱</strong>：虽叫 Local 但在慢速显存里！主要用于存放寄存器放不下的数组或发生寄存器溢出（Spilling）时。</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong><code>.const</code></strong></td>
<td style="text-align: left;">常量内存</td>
<td style="text-align: left;">显存 (DRAM)</td>
<td style="text-align: left;">Grid (只读)</td>
<td style="text-align: left;">64-bit</td>
<td style="text-align: left;">存放只读参数。有专用的 <strong>Constant Cache</strong>。<strong>特性</strong>：若 Warp 内所有线程读取同一地址（广播），速度极快；若读取分散地址，性能极差。</td>
</tr>
</tbody>
</table>
<h3 id="参数空间parameter-space">1.2 参数空间（Parameter Space）</h3>
<ul>
<li><strong><code>.param</code></strong>：用于传递函数参数和返回值。
<ul>
<li><strong>Kernel 参数</strong>：Host 启动 kernel 时传入的参数。<br />
</li>
<li><strong>Device Function 参数</strong>：GPU 内部函数调用时的栈帧传参。</li>
</ul></li>
</ul>
<h3 id="通用寻址generic-addressing">1.3 通用寻址（Generic Addressing）</h3>
<p>如果在 <code>ld</code> 指令后<strong>没有</strong>任何空间修饰符（例如直接写 <code>ld.f32 %r1, [%rd1]</code>），则表示使用<strong>通用寻址</strong>。 - <strong>机制</strong>：指针携带元数据，硬件运行时判断它指向 Global/Shared/Local。<br />
- <strong>性能</strong>：略慢于显式空间（多一步判别）。能写清楚就尽量写清楚。</p>
<hr />
<h2 id="读什么数据形状data-shape">2. 读什么：数据形状（Data Shape）</h2>
<p>这是指令的“宾语”，告诉 GPU “你要搬运的包裹长什么样”。选择正确的形状对于利用<strong>带宽</strong>至关重要。</p>
<h3 id="基本数据类型fundamental-types">2.1 基本数据类型（Fundamental Types）</h3>
<p>PTX 区分了数据的<strong>位数</strong>和<strong>解释方式</strong>：</p>
<ul>
<li><strong>无类型位宽 (<code>.b</code>)</strong>: <code>.b8</code>, <code>.b16</code>, <code>.b32</code>, <code>.b64</code>
<ul>
<li><strong>含义</strong>：纯粹的二进制搬运工，不关心里面是整数还是浮点。通常用于 <code>ld</code> 指令（因为加载时只管搬位，计算时才管类型）。</li>
<li><strong>示例</strong>：<code>ld.global.b32 %r1, [%addr];</code></li>
</ul></li>
<li><strong>有符号/无符号整数 (<code>.s</code> / <code>.u</code>)</strong>: <code>.s8</code>, <code>.s16</code>, <code>.s32</code>, <code>.s64</code> / <code>.u8</code>...
<ul>
<li><strong>含义</strong>：虽然在内存里都是二进制，但某些指令（如加载并扩展位宽）需要知道符号位。</li>
<li><strong>扩展加载</strong>：<code>ld.global.s16.s32</code> (读取一个 16 位整数，并将其符号扩展放入 32 位寄存器中)。</li>
</ul></li>
<li><strong>浮点数 (<code>.f</code>)</strong>: <code>.f16</code>, <code>.f16x2</code> (半精度), <code>.f32</code>, <code>.f64</code>
<ul>
<li><code>.f16x2</code> 是将两个 16-bit float 压缩在一个 32-bit 寄存器中，是 Tensor Core 时代的宠儿。</li>
</ul></li>
</ul>
<h3 id="向量化加载vectorized-load">2.2 向量化加载（Vectorized Load）</h3>
<p>这是<strong>性能优化</strong>最直接的手段。通过在指令中添加 <code>.v2</code> (2个), <code>.v4</code> (4个) 前缀，可以一次性吞吐更多数据。</p>
<ul>
<li><strong>语法</strong>: <code>ld.global.v4.f32 &#123;%f1, %f2, %f3, %f4&#125;, [%addr];</code>
<ul>
<li><strong>含义</strong>：从 <code>[%addr]</code> 开始，连续读取 4 个 32-bit float（共 128-bit/16-Bytes），分别存入寄存器 <code>%f1</code> 到 <code>%f4</code>。</li>
</ul></li>
<li><strong>为什么快？</strong>
<ul>
<li><strong>指令数减少</strong>：原本需要 4 条 <code>ld</code> 指令（意味着 4 次解码、4 次依赖检查），现在只要 1 条。</li>
<li><strong>带宽利用</strong>：强制硬件合并请求，极大概率生成优化的 128B Cache Line 事务。</li>
</ul></li>
<li><strong>支持规格</strong>:
<ul>
<li>最大单次加载位宽通常限制在 <strong>128-bit</strong>。</li>
<li>合法组合：<code>.v4.b32</code> (128-bit), <code>.v2.b64</code> (128-bit), <code>.v4.b16</code> (64-bit)。</li>
<li><strong>注意</strong>：<code>.v8</code> 极其罕见，通常只在特定的 Tensor Core 操作或 8-bit 量化场景下出现（如 <code>.v8.b8</code>）。</li>
</ul></li>
</ul>
<h3 id="纹理与表面类型texture-surface">2.3 纹理与表面类型（Texture &amp; Surface）</h3>
<p>这部分源自 GPU 的图形学血统，但在通用计算（尤其是图像处理、深度学习数据增强）中依然有奇效。</p>
<ul>
<li><strong><code>.tex</code> (Texture Fetch)</strong>: 纹理读取。
<ul>
<li><strong>硬件路径</strong>：数据流经专用的 <strong>Texture Cache (T-Cache)</strong>。</li>
<li><strong>空间局部性 (Spatial Locality)</strong>：普通的 Cache 优化了 1D 线性访问（读取地址 X 后，预取 X+1）。而 Texture Cache 针对 <strong>2D/3D 空间</strong>进行了优化（读取像素 (x,y) 后，会预取 (x+1, y), (x, y+1) 等周围像素）。</li>
<li><strong>免费计算</strong>：硬件在读取时可以“免费”完成以下操作：
<ul>
<li><strong>归一化</strong>: 将 <code>[0, 255]</code> 的 integer 自动转为 <code>[0.0, 1.0]</code> 的 float。</li>
<li><strong>插值</strong>: 读取坐标 <code>(1.5, 1.5)</code> 时，硬件自动根据周围 4 个像素做双线性插值返回结果。</li>
<li><strong>边界处理</strong>: 读取越界坐标时，自动执行 <code>Clamp</code>（卡在边缘）或 <code>Wrap</code>（循环）模式。</li>
</ul></li>
</ul></li>
<li><strong><code>.surf</code> (Surface Load)</strong>:
<ul>
<li>类似于纹理，但支持<strong>读写</strong>（Texture 通常只读）。通常用于操作 CUDA Array。</li>
</ul></li>
</ul>
<blockquote>
<p>所谓“免费”，就是利用专用硬件（ASIC）分担通用计算单元（ALU）的负载。在深度学习（如数据增强中的旋转缩放）和图像处理中，利用这一点可以获得巨大的加速比率性能提升。</p>
</blockquote>
<hr />
<h2 id="怎么读缓存提示caching-hints">3. 怎么读：缓存提示（Caching &amp; Hints）</h2>
<p>这是最高级、也是看起来最复杂的部分。它们是给硬件的 <strong>Cache Hints（缓存提示）</strong>。</p>
<p>与 CPU 庞大且“自作主张”的缓存系统不同，GPU 允许程序员显式控制缓存策略，告诉硬件这块数据是“热数据”（要常驻）还是“冷数据”（读完即扔），从而榨干每一滴带宽。</p>
<h3 id="图书馆模型存储层次与缓存路径">图书馆模型：存储层次与缓存路径</h3>
<p>如果你觉得术语太抽象，可以把 GPU 的存储系统想象成一个<strong>超级图书馆</strong>。</p>
<ul>
<li><strong>DRAM（显存）</strong> = <strong>地下仓库</strong>：书最全，取书最慢（几百周期）。</li>
<li><strong>L2 Cache</strong> = <strong>一楼大厅借阅架</strong>：全楼共享，所有阅览室进出都要经过。</li>
<li><strong>L1 Cache</strong> = <strong>阅览室公共书架</strong>：每个阅览室一套，近，快，但空间小。</li>
<li><strong>Shared Memory</strong> = <strong>小组白板</strong>：只给本小组用，离座位最近。</li>
</ul>
<p><strong>读（Load）的大致流程</strong>：</p>
<ol type="1">
<li><strong>查白板 (Shared)</strong>：如果你显式访问 <code>.shared</code>，直接看白板（最快，手动管理）。</li>
<li><strong>查书架 (L1)</strong>：如果你访问 <code>.global</code> 且未绕过 L1，先看部门（SM）的公共书架有没有。</li>
<li><strong>去大厅 (L2)</strong>：L1 没有（Miss）或者显式跳过 L1（<code>.cg</code>），就去大厅找。</li>
<li><strong>下仓库 (DRAM)</strong>：还没有，才去仓库搬。</li>
</ol>
<h3 id="传统缓存操作符legacy-cache-operators">3.1 传统缓存操作符（Legacy Cache Operators）</h3>
<p>这些是早期架构（如 Kepler, Maxwell）引入的简化标记，至今仍广泛兼容。为了方便记忆，我们给每个指令配一句<strong>“图书馆黑话”</strong>：</p>
<ul>
<li><strong><code>.ca</code> (Cache All)</strong>:
<ul>
<li><strong>黑话</strong>: “按规矩办。”</li>
<li><strong>策略</strong>: 尝试在 L1 和 L2 中都进行缓存。</li>
<li><strong>场景</strong>: 默认行为。适用于普适的、会被反复读取的数据。</li>
</ul></li>
<li><strong><code>.cg</code> (Cache Global)</strong>:
<ul>
<li><strong>黑话</strong>: “别占书架。”</li>
<li><strong>策略</strong>: <strong>跳过 L1，只存 L2</strong>。</li>
<li><strong>场景</strong>:
<ol type="1">
<li><strong>减少 L1 污染</strong>: 当你知道某些数据只读一次，或者数据量太大 L1 根本装不下时，直接绕过 L1，把宝贵的 L1 留给 Shared Memory 或栈变量。</li>
<li><strong>一致性</strong>: 在某些架构上 L1 不保证全局一致性，用 <code>.cg</code> 强制走 L2 可以获取最新数据。</li>
</ol></li>
</ul></li>
<li><strong><code>.cs</code> (Cache Streaming)</strong>:
<ul>
<li><strong>黑话</strong>: “我是过客。”</li>
<li><strong>策略</strong>: <strong>流式读取</strong>。暗示数据是“过客”，分配 LRU（最近最少使用）中最低的优先级，可能会被立即踢出。</li>
<li><strong>场景</strong>: 处理海量数据流（如视频解码、大矩阵一次性扫描），防止这些一次性数据把缓存里的“热数据”挤出去。</li>
</ul></li>
<li><strong><code>.lu</code> (Last Use)</strong>:
<ul>
<li><strong>黑话</strong>: “最后一眼。”</li>
<li><strong>策略</strong>: <strong>最后一次使用</strong>。读取后立即标记该 Cache Line 为“可丢弃”。</li>
<li><strong>场景</strong>: 编译器分析生命周期后，知道这是最后一次读取变量 <code>x</code>，读完就释放缓存位置。</li>
</ul></li>
<li><strong><code>.cv</code> (Cache Volatile)</strong>:
<ul>
<li><strong>黑话</strong>: “我不信二道贩子。”</li>
<li><strong>策略</strong>: <strong>不缓存</strong>（或者说视作易失）。每次必须回溯到显存读取。</li>
<li><strong>场景</strong>: 同 <code>ld.volatile</code>，用于多线程同步。</li>
</ul></li>
</ul>
<h3 id="现代-l1l2-精细控制cache-eviction-policy">3.2 现代 L1/L2 精细控制（Cache Eviction Policy）</h3>
<p>从 Volta (sm_70) 架构开始，NVIDIA 引入了更复杂的缓存控制 <code>cache-policy</code>，允许对 L1 和 L2 分别设置策略。</p>
<p><strong>格式</strong>: <code>.L1::策略</code> 或 <code>.L2::策略</code></p>
<ul>
<li><strong>Allocation Policy (分配策略)</strong>:
<ul>
<li><code>no_allocate</code>: <strong>不分配缓存</strong>。读取数据后，<strong>不将其写入</strong>指定的缓存层级（L1 或 L2），直接从更底层获取。</li>
<li><strong>黑话</strong>: "路过不占座。"</li>
<li><strong>场景</strong>:
<ol type="1">
<li><strong>避免缓存污染</strong>: 当你明确知道某个数据只读一次（如初始化数据、临时缓冲区），用 <code>.L1::no_allocate</code> 可以避免它挤占 L1 的宝贵空间，把缓存留给真正需要反复访问的热数据。</li>
<li><strong>流式处理</strong>: 处理海量数据流时，用 <code>.L2::no_allocate</code> 可以避免一次性数据把 L2 里的重要数据踢出去。</li>
</ol></li>
<li><strong>示例</strong>: <code>ld.global.L1::no_allocate.b32 %r1, [%addr];</code> 表示从 Global Memory 读取，但<strong>不缓存到 L1</strong>（可能仍会经过 L2）。</li>
</ul></li>
<li><strong>Eviction Priorities (驱逐优先级)</strong>:
<ul>
<li><code>evict_normal</code>: 正常优先级（默认）。</li>
<li><code>evict_first</code>: <strong>优先驱逐</strong>。数据读进来后，放在 LRU 队列的队尾。相当于告诉硬件："这数据我只用这一瞬间，马上可以扔。"（类似 <code>.cs</code>）</li>
<li><code>evict_last</code>: <strong>最后驱逐</strong>。数据读进来后，强行置顶到 LRU 队头。相当于："这是重要 VIP 数据，尽量别把它踢走。"</li>
</ul></li>
<li><strong>Prefetch Size (预取粒度)</strong>:
<ul>
<li><code>.L2::64B</code> / <code>.L2::128B</code> / <code>.L2::256B</code>: 显式告诉 L2 缓存控制器一次去 DRAM 搬多少数据。</li>
<li><strong>用途</strong>: 如果你知道接下来会顺序读取一大块内存，强制用 <code>.L2::256B</code> 可以减少事务数量，提升带宽。</li>
</ul></li>
</ul>
<h3 id="非一致性读取non-coherent-access">3.3 非一致性读取（Non-Coherent Access）</h3>
<ul>
<li><strong><code>.nc</code> (Non-Coherent)</strong>:
<ul>
<li><strong>机制</strong>: 借助 <strong>Texture Cache</strong> 的路径来加载全局内存。</li>
<li><strong>通俗理解（正门 vs 侧门）</strong>:
<ul>
<li>在 Kepler 等旧架构中，<strong>L1 缓存</strong>和 <strong>Texture 缓存</strong>是两条独立的物理管道。</li>
<li><strong>常规读取</strong> (<code>ld.global</code>) 走 L1 管道（正门）。</li>
<li><strong><code>.nc</code> 读取</strong> (<code>ld.global.nc</code>) 强行让数据走 Texture 管道（侧门）。</li>
</ul></li>
<li><strong>场景举例</strong>:
<ul>
<li>假设你要算 <code>C[i] = A[i] + B[i]</code>。</li>
<li><strong>拥堵</strong>：如果都用普通 <code>ld</code>，A 和 B 都要挤 L1 的带宽。</li>
<li><strong>分流</strong>：如果你把只读数组 A 用 <code>ld.global.nc</code> 读取，它就会走侧门；B 走正门。这样实现了<strong>双管齐下</strong>，总带宽更高。</li>
</ul></li>
<li><strong>代价</strong>: Texture Cache 是<strong>只读</strong>的。如果你一边从侧门读 A，一边又在 kernel 里通过正门修改 A，侧门是不会收到通知的（即“非一致性”），你可能会读到旧值。</li>
</ul></li>
</ul>
<hr />
<h2 id="正确性一致性语义与同步作用域consistency-scope">4. 正确性：一致性语义与同步作用域（Consistency &amp; Scope）</h2>
<p>很多人会把 “缓存提示” 和 “一致性/同步” 混在一起。一个好用的区分是：</p>
<ul>
<li><strong>Cache Hints（<code>.cg/.cs/.L2::...</code>）</strong>：主要影响<strong>性能</strong>，用错了通常是“慢”，不一定“错”。<br />
</li>
<li><strong>Consistency（<code>.volatile/.acquire/.release/...</code>）</strong>：主要影响<strong>正确性</strong>，用错了会出逻辑 bug（读到旧值、死锁、自旋等）。</li>
</ul>
<h3 id="内存语义semantics">4.1 内存语义（Semantics）</h3>
<p>定义了“怎么读”以及“读的时候要遵守什么规矩”。为了直观，我们用<strong>“装修队（A铺地板，B搬沙发）”</strong>来打比方：</p>
<ul>
<li><strong><code>.weak</code>（默认）</strong>：弱序。
<ul>
<li><strong>装修黑话</strong>：“各干各的。”</li>
<li><strong>后果</strong>：硬件觉得铺地和搬沙发没关系，可能先把沙发搬进去再铺地。单线程没问题，多线程会逻辑错乱。</li>
</ul></li>
<li><strong><code>.volatile</code></strong>：易失性。
<ul>
<li><strong>装修黑话</strong>：“不信传言，只问工头。”</li>
<li><strong>后果</strong>：强制绕过 L1（传言），直接去 L2/DRAM（工头）查最新的值。常用于轮询 Flag。</li>
</ul></li>
<li><strong><code>.relaxed</code></strong>：松散。
<ul>
<li>仅保证操作原子性（不会读半个数据），不保证顺序。</li>
</ul></li>
<li><strong><code>.acquire</code></strong>：获取语义（单向栅栏）。
<ul>
<li><strong>装修黑话</strong>：“听到才动。”</li>
<li><strong>后果</strong>：B 线程保证“听到 A 完工的信号之前，绝不搬沙发”。禁止后续读写重排到前面。</li>
</ul></li>
<li><strong><code>.release</code></strong>（对应 st 指令）：发布语义。
<ul>
<li><strong>装修黑话</strong>：“做完才喊。”</li>
<li><strong>后果</strong>：A 线程保证“喊完工之前，地板一定铺好了”。禁止前面读写重排到后面。</li>
</ul></li>
<li><strong><code>.mmio</code></strong>：内存映射 I/O 场景。</li>
</ul>
<h3 id="同步作用域scope">4.2 同步作用域（Scope）</h3>
<ul>
<li><strong><code>.cta</code></strong>：Block/CTA 内。<br />
</li>
<li><strong><code>.gpu</code></strong>：整张 GPU（跨 Block）。<br />
</li>
<li><strong><code>.sys</code></strong>：系统范围（含 CPU/其他 GPU）。<br />
</li>
<li><strong><code>.cluster</code></strong>：Hopper 的 Thread Block Cluster。</li>
</ul>
<blockquote>
<p><strong>Cluster 扩展知识 (Hopper 新特性, H100, Compute Capability 9.0)</strong>： * <strong>层级位置</strong>：位于 Grid 和 Block 之间 (Grid &gt; Cluster &gt; Block &gt; Thread)。 * <strong>物理含义</strong>：保证一组 Block（如 4 个）被调度到<strong>物理相邻</strong>的 SM 上（GPC 内部）。 * <strong>解决痛点</strong>：Block 和 Block 之间是完全隔离的。哪怕 Block A 和 Block B 就在隔壁的两个 SM 上运行，它们想交换数据，也必须走最慢的 Global Memory。 * <strong>超能力</strong>：Cluster 内的不同 Block 可以直接访问对方的 Shared Memory（称为 <strong>DSMEM</strong>），通信不用绕道 L2，极其适合大模型训练中跨 Block 的数据交换。 <em>把属于同一个 Cluster 的所有 Block，调度到同一个 GPC里的不同 SM上去。</em></p>
</blockquote>
<p>典型组合：</p>
<ul>
<li><code>ld.global.acquire.gpu.b32 %r1, [%addr];</code>：从全局内存读 32 位，并在 GPU 范围内按 acquire 语义约束重排。</li>
</ul>
<hr />
<h2 id="操作数细节写-ptx-时最常见的几种地址形式">5. 操作数细节：写 PTX 时最常见的几种地址形式</h2>
<p>在 <code>ld</code> 指令中，通常遵循 <strong>目标 (Destination) &lt;--- 源 (Source)</strong> 的顺序。</p>
<h3 id="目标操作数destination">5.1 目标操作数（Destination）</h3>
<ul>
<li><strong>寄存器（<code>d</code>）</strong>：如 <code>%r1/%f2/%p0</code>。PTX 使用无限的虚拟寄存器，后端会映射到有限的物理寄存器。<br />
</li>
<li><strong>向量化接收</strong>：例如 <code>ld.global.v4.f32 &#123;%f0, %f1, %f2, %f3&#125;, [%addr];</code>。</li>
</ul>
<h3 id="源地址address">5.2 源地址（Address）</h3>
<ul>
<li><strong>直接地址</strong>：<code>[%rd1]</code>（常见 64-bit 指针）或 <code>[%r1]</code>（32-bit）。<br />
</li>
<li><strong>立即数偏移</strong>：<code>[%rd1 + 128]</code>（硬件的 base+offset 寻址，通常很划算）。<br />
</li>
<li><strong>符号名</strong>：<code>[my_global_array]</code>（全局变量名）。</li>
</ul>
<h3 id="特殊形式">5.3 特殊形式</h3>
<ul>
<li><strong>通用寻址</strong>：省略状态空间后缀（硬件运行时判别）。<br />
</li>
<li><strong>动态 cache-policy</strong>：某些指令允许运行时传入策略掩码（更高阶用法）。</li>
</ul>
<h2 id="学习路线从能用到能调优">6. 学习路线（从能用到能调优）</h2>
<ol type="1">
<li><strong>Level 1（基础）</strong>：搞懂 <code>ld.global / ld.shared</code> + 基础类型（<code>.b32/.f32/.s32</code>）。<br />
</li>
<li><strong>Level 2（性能）</strong>：搞懂向量化 <code>.v2/.v4</code>（指令数与带宽利用率）。<br />
</li>
<li><strong>Level 3（专家）</strong>：理解 <code>.ca/.cg/.cs/.lu</code> 与 <code>.L1/.L2</code> 驱逐/预取策略（减少缓存污染）。<br />
</li>
<li><strong>Level 4（并发）</strong>：理解 <code>.acquire/.release/.volatile</code> 与 scope（避免读旧值/重排导致的逻辑错误）。</li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/posts/8af06056/" rel="prev" title="LaTeX 编译原理与指令指南">
                  <i class="fa fa-angle-left"></i> LaTeX 编译原理与指令指南
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa-solid fa-headphones"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">吃糠咽菜</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">229k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">6:56</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
